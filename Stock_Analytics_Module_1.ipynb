{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFnpuQMpdLpvhwvmAv5Mrn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dollygpt05/Dollygpt05/blob/main/Stock_Analytics_Module_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Created a dataframe"
      ],
      "metadata": {
        "id": "eT79wxa7tvjn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5K7I0X3z47Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7-QdWeai5iJ",
        "outputId": "34a252c2-acd2-47c9-b5fb-4fd04777680a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Symbol             Security             GICS Sector  \\\n",
            "0    MMM                   3M             Industrials   \n",
            "1    AOS          A. O. Smith             Industrials   \n",
            "2    ABT  Abbott Laboratories             Health Care   \n",
            "3   ABBV               AbbVie             Health Care   \n",
            "4    ACN            Accenture  Information Technology   \n",
            "\n",
            "                GICS Sub-Industry    Headquarters Location  Date added  \\\n",
            "0        Industrial Conglomerates    Saint Paul, Minnesota  1957-03-04   \n",
            "1               Building Products     Milwaukee, Wisconsin  2017-07-26   \n",
            "2           Health Care Equipment  North Chicago, Illinois  1957-03-04   \n",
            "3                   Biotechnology  North Chicago, Illinois  2012-12-31   \n",
            "4  IT Consulting & Other Services          Dublin, Ireland  2011-07-06   \n",
            "\n",
            "       CIK      Founded  \n",
            "0    66740         1902  \n",
            "1    91142         1916  \n",
            "2     1800         1888  \n",
            "3  1551152  2013 (1888)  \n",
            "4  1467373         1989  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
        "tables = pd.read_html(url)  # Returns a list of DataFrames\n",
        "\n",
        "# View the first table\n",
        "SNP500= tables[0]\n",
        "print(SNP500.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extrated a relevent columns"
      ],
      "metadata": {
        "id": "0jJJchjtt026"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = SNP500[['Symbol', 'Security', 'Date added']]\n",
        "print (A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SB_uDA9lCsV",
        "outputId": "77c8bb35-f1ac-4382-c496-a3b82f6b0db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Symbol             Security  Date added\n",
            "0      MMM                   3M  1957-03-04\n",
            "1      AOS          A. O. Smith  2017-07-26\n",
            "2      ABT  Abbott Laboratories  1957-03-04\n",
            "3     ABBV               AbbVie  2012-12-31\n",
            "4      ACN            Accenture  2011-07-06\n",
            "..     ...                  ...         ...\n",
            "498    XYL           Xylem Inc.  2011-11-01\n",
            "499    YUM          Yum! Brands  1997-10-06\n",
            "500   ZBRA   Zebra Technologies  2019-12-23\n",
            "501    ZBH        Zimmer Biomet  2001-08-07\n",
            "502    ZTS               Zoetis  2013-06-21\n",
            "\n",
            "[503 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First highest addition was in 1957 when S&P started, the second highest is 2016 with 23 additions in a year."
      ],
      "metadata": {
        "id": "miu3lNzvt6ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A.loc['Date added'] = pd.to_datetime(A['Date added'], errors='coerce')\n",
        "A.loc[:, 'Year added'] = A['Date added'].dt.year\n",
        "year_counts = A['Year added'].value_counts().sort_index()\n",
        "\n",
        "most_additions_year = year_counts.idxmax()\n",
        "most_additions_count = year_counts.max()\n",
        "\n",
        "\n",
        "print(f\"Year with most additions: {most_additions_year}\")\n",
        "print(f\"Number of additions: {most_additions_count}\")\n",
        "\n",
        "top_years = year_counts.sort_values(ascending=False)\n",
        "second_highest_year = top_years.index[1]\n",
        "second_highest_count = top_years.iloc[1]\n",
        "print(f\"2nd: {second_highest_year} ({second_highest_count} additions)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBEhPXN0n_KR",
        "outputId": "38769964-9ee6-4546-f0e7-a7ca9ba7ed98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Year with most additions: 1957.0\n",
            "Number of additions: 53\n",
            "2nd: 2016.0 (23 additions)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2\n",
        "Question 2 importing data from yahoo finance\n"
      ],
      "metadata": {
        "id": "rGWNtwv-JEC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install main library YFinance\n",
        "!pip install yfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eduxVlq1cJC",
        "outputId": "8690069b-63f8-4bce-edb4-2d0652a07dc6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.61)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.11.1)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.4)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Fin Data Sources\n",
        "import yfinance as yf\n",
        "import pandas_datareader as pdr\n",
        "\n",
        "#Data viz\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px\n",
        "\n",
        "import time\n",
        "from datetime import date"
      ],
      "metadata": {
        "id": "kD78_N6o1smc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "ZcBwzXu14z9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "end = date(2025, 5, 1)\n",
        "print(f'Year = {end.year}; month= {end.month}; day={end.day}')\n",
        "\n",
        "start = date(year=end.year, month=1, day=1)\n",
        "print(f'Period for indexes: {start} to {end} ')\n",
        "\n",
        "# List of 10 global stock indexes (tickers used by Yahoo Finance)\n",
        "index_tickers = {\n",
        "    '^GSPC': 'S&P 500 (USA)',\n",
        "    '^FTSE': 'FTSE 100 (UK)',\n",
        "    '^N225': 'Nikkei 225 (Japan)',\n",
        "    '^GDAXI': 'DAX (Germany)',\n",
        "    '^FCHI': 'CAC 40 (France)',\n",
        "    '^HSI': 'Hang Seng (Hong Kong)',\n",
        "    '^STI': 'Straits Times (Singapore)',\n",
        "    '^AXJO': 'ASX 200 (Australia)',\n",
        "    '^BVSP': 'Bovespa (Brazil)',\n",
        "    '^NSEI': 'Nifty 50 (India)'\n",
        "}\n",
        "\n",
        "returns = {}\n",
        "\n",
        "# Fetch and calculate YTD returns for each index\n",
        "for ticker, name in index_tickers.items():\n",
        "    try:\n",
        "        data = yf.Ticker(ticker).history(start=start, end=end)\n",
        "        if not data.empty:\n",
        "            start_price = data['Close'].iloc[0]\n",
        "            end_price = data['Close'].iloc[-1]\n",
        "            ytd_return = ((end_price - start_price) / start_price) * 100\n",
        "            returns[ticker] = ytd_return\n",
        "            print(f\"{name}: {ytd_return:.2f}%\")\n",
        "        else:\n",
        "            print(f\"{name}: No data\")\n",
        "    except Exception as e:\n",
        "        print(f\"{name}: Error fetching data - {e}\")\n",
        "\n",
        "# Compare with S&P 500\n",
        "sp500_return = returns.get('^GSPC', None)\n",
        "\n",
        "if sp500_return is not None:\n",
        "    better_than_sp500 = sum(1 for t, r in returns.items() if t != '^GSPC' and r > sp500_return)\n",
        "    print(f\"\\nNumber of indexes with better YTD returns than the S&P 500: {better_than_sp500} out of 9\")\n",
        "else:\n",
        "    print(\"\\nS&P 500 data unavailable, comparison cannot be made.\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC9jenW613z5",
        "outputId": "5b9b8a07-909f-435f-889d-4de5c275f863"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Year = 2025; month= 5; day=1\n",
            "Period for indexes: 2025-01-01 to 2025-05-01 \n",
            "S&P 500 (USA): -5.10%\n",
            "FTSE 100 (UK): 2.84%\n",
            "Nikkei 225 (Japan): -8.30%\n",
            "DAX (Germany): 12.35%\n",
            "CAC 40 (France): 2.71%\n",
            "Hang Seng (Hong Kong): 12.72%\n",
            "Straits Times (Singapore): 0.83%\n",
            "ASX 200 (Australia): -0.91%\n",
            "Bovespa (Brazil): 12.44%\n",
            "Nifty 50 (India): 2.49%\n",
            "\n",
            "Number of indexes with better YTD returns than the S&P 500: 8 out of 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest was in Hong Kong, followed by Brazil"
      ],
      "metadata": {
        "id": "PXfny1DK4bfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3. [Index] S&P 500 Market Corrections Analysis"
      ],
      "metadata": {
        "id": "wVMlSGFH5Anh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import S&P 500 data from 1950 to present"
      ],
      "metadata": {
        "id": "mjRodwrTagYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "from datetime import date\n",
        "\n",
        "# Define the date range\n",
        "start_date = \"1950-01-01\"\n",
        "end_date = date.today().strftime('%Y-%m-%d')  # today's date\n",
        "\n",
        "# Download historical data for the S&P 500 index (^GSPC)\n",
        "sp500_data = yf.download(\"^GSPC\", start=start_date, end=end_date)\n",
        "\n",
        "# Display first few rows\n",
        "print(sp500_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c70ufGuN5LJP",
        "outputId": "3f825f06-7372-474d-c9d1-8c7270d72714"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price       Close   High    Low   Open   Volume\n",
            "Ticker      ^GSPC  ^GSPC  ^GSPC  ^GSPC    ^GSPC\n",
            "Date                                           \n",
            "1950-01-03  16.66  16.66  16.66  16.66  1260000\n",
            "1950-01-04  16.85  16.85  16.85  16.85  1890000\n",
            "1950-01-05  16.93  16.93  16.93  16.93  2550000\n",
            "1950-01-06  16.98  16.98  16.98  16.98  2010000\n",
            "1950-01-09  17.08  17.08  17.08  17.08  2520000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify all-time high points (where price exceeds all previous prices)"
      ],
      "metadata": {
        "id": "hxDCguEvao-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import date\n",
        "\n",
        "# Step 1: Download S&P 500 historical data\n",
        "start_date = \"1950-01-01\"\n",
        "end_date = date.today().strftime('%Y-%m-%d')\n",
        "data = yf.download(\"^GSPC\", start=start_date, end=end_date)\n",
        "\n",
        "# 🛠 Step 1.5: Flatten column names (fixes the KeyError issue)\n",
        "if isinstance(data.columns, pd.MultiIndex):\n",
        "    data.columns = [col[0] for col in data.columns]\n",
        "\n",
        "# Step 2: Remove rows where 'Close' is missing\n",
        "data = data.dropna(subset=['Close'])\n",
        "\n",
        "# Step 3: Identify all-time high closing prices\n",
        "data['ATH'] = data['Close'].cummax()\n",
        "\n",
        "# Step 4: Keep only all-time high dates\n",
        "ath_data = data[data['Close'] == data['ATH']].copy().reset_index()\n",
        "\n",
        "# Step 5: Analyze each pair of ATHs\n",
        "results = []\n",
        "for i in range(len(ath_data) - 1):\n",
        "    start_date = ath_data.loc[i, 'Date']\n",
        "    end_date = ath_data.loc[i + 1, 'Date']\n",
        "    between = data.loc[start_date:end_date].iloc[1:-1]\n",
        "\n",
        "    if not between.empty:\n",
        "        min_price = between['Close'].min()\n",
        "        min_date = between['Close'].idxmin()\n",
        "        high_price = ath_data.loc[i, 'Close']\n",
        "        drawdown = (high_price - min_price) / high_price * 100\n",
        "        duration = (end_date - start_date).days\n",
        "\n",
        "        results.append({\n",
        "            'Start ATH': start_date,\n",
        "            'Next ATH': end_date,\n",
        "            'Lowest Date': min_date,\n",
        "            'High Price': high_price,\n",
        "            'Low Price': min_price,\n",
        "            'Drawdown (%)': drawdown,\n",
        "            'Duration (days)': duration\n",
        "        })\n",
        "\n",
        "# Step 6: Create results DataFrame\n",
        "drawdowns = pd.DataFrame(results)\n",
        "\n",
        "# Step 7: Filter for drawdowns ≥ 5%\n",
        "corrections = drawdowns[drawdowns['Drawdown (%)'] >= 5]\n",
        "\n",
        "# Step 8: Show first few corrections\n",
        "print(\"\\nCorrections ≥ 5% drawdown:\")\n",
        "print(corrections[['Start ATH', 'Next ATH', 'Drawdown (%)', 'Duration (days)']].head())\n",
        "\n",
        "# Step 9: Show correction duration percentiles\n",
        "percentiles = corrections['Duration (days)'].quantile([0.25, 0.5, 0.75])\n",
        "print(\"\\n📊 Correction duration percentiles:\")\n",
        "print(percentiles)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlBgSYD_32nh",
        "outputId": "3fab6997-d5f0-4e29-8812-1b236ced1fd2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Corrections ≥ 5% drawdown:\n",
            "    Start ATH   Next ATH  Drawdown (%)  Duration (days)\n",
            "16 1950-06-12 1950-09-22     14.020615              102\n",
            "21 1950-11-24 1950-12-28      6.496062               34\n",
            "28 1951-05-03 1951-08-02      8.110480               91\n",
            "33 1951-10-15 1952-01-03      6.079668               80\n",
            "36 1952-01-22 1952-06-25      6.366584              155\n",
            "\n",
            "📊 Correction duration percentiles:\n",
            "0.25     56.0\n",
            "0.50     94.0\n",
            "0.75    213.5\n",
            "Name: Duration (days), dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4. [Stocks] Earnings Surprise Analysis for Amazon (AMZN)# New Section"
      ],
      "metadata": {
        "id": "CDLfq_t14GPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the raw GitHub URL\n",
        "url = \"https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/cohorts/2025/ha1_Amazon.csv\"\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "\n",
        "df = pd.read_csv(url, on_bad_lines=\"skip\")\n",
        "\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "# Define the stock ticker (e.g., Amazon)\n",
        "ticker = \"AMZN\"\n",
        "\n",
        "# Download historical data (adjust the period as needed)\n",
        "df = yf.download(ticker, period=\"max\")  # 'max' fetches full available history\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Define the stock ticker\n",
        "ticker = \"AMZN\"\n",
        "\n",
        "# Download historical stock data\n",
        "df = yf.download(ticker, period=\"max\")\n",
        "\n",
        "# Compute the 2-day percentage change\n",
        "df[\"Return_2d\"] = df[\"Close\"].shift(-2) / df[\"Close\"] - 1\n",
        "\n",
        "# Display relevant columns\n",
        "print(df[[\"Close\", \"Return_2d\"]].dropna().head())\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "# Define the stock ticker\n",
        "ticker = \"AMZN\"\n",
        "\n",
        "# Get earnings history\n",
        "stock = yf.Ticker(ticker)\n",
        "earnings = stock.earnings_dates\n",
        "\n",
        "# Filter for positive earnings surprises\n",
        "positive_surprises = earnings[(earnings[\"Surprise(%)\"] > 0) | (earnings[\"Reported EPS\"] > earnings[\"EPS Estimate\"])]\n",
        "\n",
        "# Display results\n",
        "print(positive_surprises)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90tWUsfkm-CS",
        "outputId": "4a37f20c-4dbc-4fba-fe8e-2d46622c2a3f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               Symbol;Company;Earnings Date;EPS Estimate;Reported EPS;Surprise (%)\n",
            "AMZN;Amazon.com Inc;April 29                               2026 at 6 AM EDT;-;-;-                 \n",
            "AMZN;Amazon.com Inc;February 4                             2026 at 4 PM EST;-;-;-                 \n",
            "AMZN;Amazon.com Inc;October 29                             2025 at 6 AM EDT;-;-;-                 \n",
            "AMZN;Amazon.com Inc;July 30                                2025 at 4 PM EDT;-;-;-                 \n",
            ";;;;;                                                                         NaN                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price          Close      High       Low      Open      Volume\n",
            "Ticker          AMZN      AMZN      AMZN      AMZN        AMZN\n",
            "Date                                                          \n",
            "1997-05-15  0.097917  0.125000  0.096354  0.121875  1443120000\n",
            "1997-05-16  0.086458  0.098958  0.085417  0.098438   294000000\n",
            "1997-05-19  0.085417  0.088542  0.081250  0.088021   122136000\n",
            "1997-05-20  0.081771  0.087500  0.081771  0.086458   109344000\n",
            "1997-05-21  0.071354  0.082292  0.068750  0.081771   377064000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price          Close Return_2d\n",
            "Ticker          AMZN          \n",
            "Date                          \n",
            "1997-05-15  0.097917 -0.127659\n",
            "1997-05-16  0.086458 -0.054211\n",
            "1997-05-19  0.085417 -0.164639\n",
            "1997-05-20  0.081771 -0.146494\n",
            "1997-05-21  0.071354  0.051097\n",
            "                           EPS Estimate  Reported EPS  Surprise(%)\n",
            "Earnings Date                                                     \n",
            "2025-05-01 16:01:00-04:00          1.36          1.59        16.73\n",
            "2025-02-06 16:01:00-05:00          1.49          1.86        24.47\n",
            "2024-10-31 16:01:00-04:00          1.14          1.43        25.17\n",
            "2024-08-01 16:01:00-04:00          1.03          1.26        22.58\n",
            "2024-04-30 16:01:00-04:00          0.83          0.98        17.91\n",
            "2024-02-01 16:00:00-05:00          0.80          1.00        24.55\n",
            "2023-10-26 16:01:00-04:00          0.58          0.94        60.85\n",
            "2023-08-03 16:01:00-04:00          0.35          0.65        85.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate 2-day percentage changes following positive earnings surprises. Show your answer in % (closest number to the 2nd digit): return * 100."
      ],
      "metadata": {
        "id": "FFEI9Cp3sbHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/cohorts/2025/ha1_Amazon.csv\"\n",
        "df = pd.read_csv(url, sep=';')\n",
        "\n",
        "# Clean column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Print column names\n",
        "print(\"Column names:\", df.columns.tolist())\n",
        "\n",
        "# Check for 'Earnings Date' column\n",
        "if 'Earnings Date' in df.columns:\n",
        "    print(\"'Earnings Date' column is present.\")\n",
        "else:\n",
        "    print(\"'Earnings Date' column is missing.\")\n",
        "\n",
        "# Remove unrecognized timezones (EDT, EST)\n",
        "df['Earnings Date Clean'] = df['Earnings Date'].str.replace(r'\\s+(EDT|EST)', '', regex=True)\n",
        "\n",
        "# Convert to datetime\n",
        "df['Earnings Date'] = pd.to_datetime(df['Earnings Date Clean'])\n",
        "\n",
        "# Sort by earnings date\n",
        "df = df.sort_values('Earnings Date').reset_index(drop=True)\n",
        "\n",
        "# Filter for positive earnings surprises\n",
        "df['Reported EPS'] = pd.to_numeric(df['Reported EPS'], errors='coerce')\n",
        "df['EPS Estimate'] = pd.to_numeric(df['EPS Estimate'], errors='coerce')\n",
        "\n",
        "positive_earnings = df[df['Reported EPS'] > df['EPS Estimate']].copy()\n",
        "\n",
        "# Show relevant info\n",
        "print(\"\\nPositive Earnings Surprises:\")\n",
        "print(positive_earnings[['Earnings Date', 'Reported EPS', 'EPS Estimate', 'Surprise (%)']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EZE4XdJ0Bkw",
        "outputId": "ee63d67f-8a15-4ba3-d6eb-71e138d17f64"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names: ['Symbol', 'Company', 'Earnings Date', 'EPS Estimate', 'Reported EPS', 'Surprise (%)']\n",
            "'Earnings Date' column is present.\n",
            "\n",
            "Positive Earnings Surprises:\n",
            "          Earnings Date  Reported EPS  EPS Estimate Surprise (%)\n",
            "34  2006-02-02 00:00:00          0.02          0.01      +120.86\n",
            "44  2008-07-23 00:00:00          0.02          0.01       +42.09\n",
            "46  2009-01-29 00:00:00          0.03          0.02        +33.2\n",
            "53  2010-10-21 00:00:00          0.03          0.02        +7.28\n",
            "54  2011-01-27 00:00:00          0.05          0.04        +3.03\n",
            "58  2012-01-31 00:00:00          0.02          0.01          127\n",
            "70  2015-01-29 16:00:00          0.02          0.01      +168.18\n",
            "72  2015-07-23 16:00:00          0.01         -0.01      +237.28\n",
            "73  2015-10-22 16:00:00          0.01         -0.01      +225.37\n",
            "75  2016-04-28 16:00:00          0.05          0.03       +81.42\n",
            "76  2016-07-28 16:00:00          0.09          0.06       +60.65\n",
            "78  2017-02-02 16:00:00          0.08          0.07       +14.35\n",
            "79  2017-04-27 16:00:00          0.07          0.05       +36.46\n",
            "82  2018-02-01 16:00:00          0.11          0.09       +17.33\n",
            "83  2018-04-26 16:00:00          0.16          0.06      +159.65\n",
            "84  2018-07-26 16:00:00          0.25          0.13       +99.84\n",
            "85  2018-10-25 16:00:00          0.29          0.16       +82.98\n",
            "86  2019-01-31 16:00:00          0.30          0.28        +6.34\n",
            "87  2019-04-25 16:00:00          0.35          0.24       +50.11\n",
            "90  2020-01-30 16:00:00          0.32          0.20       +60.62\n",
            "92  2020-07-30 16:00:00          0.52          0.07      +605.29\n",
            "93  2020-10-29 16:00:00          0.62          0.37       +66.95\n",
            "94  2021-02-02 16:00:00          0.70          0.36       +94.84\n",
            "95  2021-04-29 16:00:00          0.79          0.48       +65.48\n",
            "96  2021-07-29 16:00:00          0.76          0.62       +22.91\n",
            "98  2022-02-03 16:00:00          0.29          0.18       +62.48\n",
            "100 2022-07-28 16:00:00          0.18          0.14        +24.9\n",
            "102 2023-02-02 16:00:00          0.25          0.18       +42.56\n",
            "103 2023-04-27 16:00:00          0.31          0.21       +46.36\n",
            "104 2023-08-03 16:00:00          0.65          0.35       +85.73\n",
            "105 2023-10-26 16:00:00          0.94          0.58       +60.85\n",
            "106 2024-02-01 16:00:00          1.00          0.80       +24.55\n",
            "107 2024-04-30 16:00:00          0.98          0.83       +17.91\n"
          ]
        }
      ]
    }
  ]
}